# Data loader configuration
data:
  dataset: "amazon"
  batch_size: 256
  normalize_data: False
  category: "beauty"

# Model configuration
model:
  input_dimension: 768 # computed automatically later
  hidden_dimensions: [768, 512, 256, 128]
  latent_dimension: 128
  num_codebook_layers: 3
  codebook_clusters: 256
  commitment_weight: 0.25

# Training configuration
train:
  learning_rate: 5e-4
  weight_decay: 1e-4
  num_epochs: 256

# Additional configuration
general:
  use_wandb: True
  wandb_project: "semantic_id_amazon"
  wandb_entity: "justin-hangoebl-master-thesis"
  save_model: True
